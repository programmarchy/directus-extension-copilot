```typescript
import { ChatOpenAI } from "langchain/chat_models/openai";
import { HumanMessage, ChatMessage, SystemMessage } from "langchain/schema";

const chat = new ChatOpenAI({
  temperature: 0
});

const result = await chat.predictMessages([
  new HumanMessage("Translate this sentence from English to French. I love programming.")
]);

/*
  AIMessage {
    content: "J'adore la programmation."
  }
*/
```

It is useful to understand how chat models are different from a normal LLM, but it can often be handy to just be able to treat them the same.
LangChain makes that easy by also exposing an interface through which you can interact with a chat model as you would a normal LLM.
You can access this through the `predict` interface.

```typescript
const result = await chat.predict("Translate this sentence from English to French. I love programming.")
// "J'adore la programmation."
```
